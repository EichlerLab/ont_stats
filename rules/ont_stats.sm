"""
Generate sequencing stats for ONT data.
"""


#
# Rules
#

# ont_stats_merge_cell
#
# Merge cell stats
rule ont_stats_merge_cell:
    input:
        tsv=input_all_sample_cell_summary_row
    output:
        tsv='samples/{sample}/cell_summary.tsv.gz',
        xlsx='samples/{sample}/cell_summary.xlsx'
    run:

        # Merge and write
        df = pd.concat(
            [pd.read_csv(tsv_file, sep='\t', header=0) for tsv_file in input.tsv]
        )

        df.to_csv(output.tsv, sep='\t', index=False, compression='gzip')
        df.to_excel(output.xlsx, index=False)


# ont_stats_merge_sample
#
# Calculate stats for the whole sample
rule ont_stats_merge_sample:
    input:
        tsv=input_all_sample_cell_read_table
    output:
        tsv='samples/{sample}/sample_summary.tsv.gz',
        xlsx='samples/{sample}/sample_summary.xlsx'
    run:

        df_cell = get_cell_table(wildcards.sample)

        # Read
        df = pd.concat(
            [
                pd.read_csv(file_name, sep='\t', usecols=('LEN', 'QV'))
                    for file_name in input.tsv
            ]
        )

        # Summarize
        df_summary = pd.DataFrame(pd.Series(
            [
                wildcards.sample,
                len(input.tsv),
                df.shape[0],
                np.sum(df['LEN']),

                np.mean(df['LEN']),
                np.median(df['LEN']),
                ontstatlib.util.get_n50(df['LEN']),

                np.min(df['LEN']),
                np.max(df['LEN']),
                np.std(df['LEN']),

                np.sum(df['LEN'] >= 10000),  # 10 kbp
                np.sum(df.loc[df['LEN'] >= 10000, 'LEN']),

                np.sum(df['LEN'] >= 100000), # 100 kbp
                np.sum(df.loc[df['LEN'] >= 100000, 'LEN']),

                np.sum(df['LEN'] >= 1000000), # 1 Mbp
                np.sum(df.loc[df['LEN'] >= 1000000, 'LEN']),

                np.mean(df['QV']),
                np.median(df['QV']),
                np.max(df['QV'])
            ],
            index=[
                'SAMPLE',
                'N_CELL', 'N', 'SUM',
                'MEAN', 'MED', 'N50',
                'MIN', 'MAX', 'SD',
                'N_10K', 'SUM_10K',
                'N_100K', 'SUM_100K',
                'N_1M', 'SUM_1M',
                'QV_MEAN', 'QV_MED', 'QV_MAX'
            ]
        )).T

        # Write
        df_summary.to_csv(output.tsv, sep='\t', index=False, compression='gzip')
        df_summary.to_excel(output.xlsx, index=False)


# ont_stats
#
# Get stats per subread.
rule ont_stats:
    input:
        data_cell=cell_table_checkpoint
    output:
        tsv_summary=protected('samples/{sample}/cells/{cell}/cell_summary_row.tsv.gz'),
        tsv_reads=protected('samples/{sample}/cells/{cell}/read_table.tsv.gz')
    run:

        df_cell = get_cell_table(wildcards.sample, do_checkpoint=False)[['CELL', 'DATA']].set_index('CELL').squeeze()

        if wildcards.cell not in df_cell:
            raise RuntimeError(f'No sequence data file for sample {wildcards.sample} cell {wildcardl.cell}')

        # Get subread file
        seq_file = df_cell.loc[wildcards.cell]

        # Get stats table
        if seq_file.lower().endswith('.bam'):
            df = ontstatlib.stats.stats_table_bam(seq_file)

        elif seq_file.lower().endswith('.fastq') or seq_file.lower().endswith('.fastq.gz'):
            df = ontstatlib.stats.stats_table_fastq(seq_file)

        else:
            raise RuntimeError(f'Sequence file does not end with ".bam", ".fastq", or ".fastq.gz": {seq_file}')

        # Write ZMW table
        df.to_csv(output.tsv_reads, sep='\t', index=False, compression='gzip')

        # Summarize by cell
        df_summary = pd.DataFrame(pd.Series(
            [
                wildcards.cell,
                df.shape[0],
                np.sum(df['LEN']),

                np.mean(df['LEN']),
                np.median(df['LEN']),
                ontstatlib.util.get_n50(df['LEN']),

                np.min(df['LEN']),
                np.max(df['LEN']),
                np.std(df['LEN']),

                np.sum(df['LEN'] >= 10000),  # 10 kbp
                np.sum(df.loc[df['LEN'] >= 10000, 'LEN']),

                np.sum(df['LEN'] >= 100000), # 100 kbp
                np.sum(df.loc[df['LEN'] >= 100000, 'LEN']),

                np.sum(df['LEN'] >= 1000000), # 1 Mbp
                np.sum(df.loc[df['LEN'] >= 1000000, 'LEN']),

                np.mean(df['QV']),
                np.median(df['QV']),
                np.max(df['QV'])
            ],
            index=[
                'CELL', 'N', 'SUM',
                'MEAN', 'MED', 'N50',
                'MIN', 'MAX', 'SD',
                'N_10K', 'SUM_10K',
                'N_100K', 'SUM_100K',
                'N_1M', 'SUM_1M',
                'QV_MEAN', 'QV_MED', 'QV_MAX'
            ]
        )).T

        # Write
        df_summary.to_csv(output.tsv_summary, sep='\t', index=False, compression='gzip')
